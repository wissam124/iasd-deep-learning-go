{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepLearningProject.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wissam124/iasd-deep-learning-go/blob/master/DeepLearningProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-w-DMKhyuAv",
        "colab_type": "text"
      },
      "source": [
        "### Deep Learning Project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cKxx5Sp04Lo",
        "colab_type": "text"
      },
      "source": [
        "This is the page for the Deep Learning Project of the master IASD. The goal is to train a network for playing the game of Go. In order to be fair about training ressources the number of parameters for the networks you submit must be lower than 1 000 000. The maximum number of students per team is two. The data used for training comes from Facebook ELF opengo Go program self played games. There are more than 98 000 000 different states in total in the training set. The input data is composed of 8 19x19 planes (color to play, ladders, current state on two planes, two previous states on four planes). The output targets are the policy (a vector of size 361 with 1.0 for the move played, 0.0 for the other moves), the value (1.0 if White won, 0.0 if Black won) and the state at the end of the game (two planes)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c31YVw4RxfU4",
        "colab_type": "code",
        "outputId": "58cda924-c0e8-4376-cb9f-50b70b1ef6f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "!wget https://www.lamsade.dauphine.fr/~cazenave/DeepLearningProject.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-12-12 20:09:52--  https://www.lamsade.dauphine.fr/~cazenave/DeepLearningProject.zip\n",
            "Resolving www.lamsade.dauphine.fr (www.lamsade.dauphine.fr)... 193.48.71.250\n",
            "Connecting to www.lamsade.dauphine.fr (www.lamsade.dauphine.fr)|193.48.71.250|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 211774472 (202M) [application/zip]\n",
            "Saving to: ‘DeepLearningProject.zip’\n",
            "\n",
            "DeepLearningProject 100%[===================>] 201.96M  32.1MB/s    in 6.9s    \n",
            "\n",
            "2019-12-12 20:10:05 (29.2 MB/s) - ‘DeepLearningProject.zip’ saved [211774472/211774472]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlFlboq_yzSk",
        "colab_type": "code",
        "outputId": "d415c1ce-a9bd-421a-d160-7e4a7ce11d6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        }
      },
      "source": [
        "!unzip -j DeepLearningProject.zip\n",
        "# Copy all files into root directory\n",
        "# !cp -r DeepLearningProject/* ."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  DeepLearningProject.zip\n",
            "  inflating: Board.h                 \n",
            "  inflating: Game.h                  \n",
            "  inflating: Rzone.h                 \n",
            "  inflating: compileMAC.sh           \n",
            "  inflating: compile.sh              \n",
            "  inflating: ls.sh                   \n",
            "  inflating: golois.cpp              \n",
            "  inflating: games.data              "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V85wNDFey-V3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls -all"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Md7ZkvCp-aK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -r golois.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mq7X6QBxpfAn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip3 install pybind11"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07WmuLhUpWzp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!./compile.sh"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pqfzmfn7zqgq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Input, Dense, Conv2D, Flatten, BatchNormalization, Activation, LeakyReLU, add, SpatialDropout2D\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.callbacks import CSVLogger\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "class GoModel():\n",
        "    def __init__(self, regParam, learningRate, inputDim, outputDim):\n",
        "        self.regParam = regParam\n",
        "        self.learningRate = learningRate\n",
        "        self.inputDim = inputDim\n",
        "        self.outputDim = outputDim\n",
        "\n",
        "    def predict(self, x):\n",
        "        return self.model.predict(x)\n",
        "\n",
        "    def fit(self, X, y, epochs, verbose, validation_split, batch_size):\n",
        "        checkpoint = ModelCheckpoint('best_model.h5',\n",
        "                                     monitor='loss',\n",
        "                                     verbose=1,\n",
        "                                     save_best_only=True,\n",
        "                                     mode='auto',\n",
        "                                     period=1)\n",
        "\n",
        "        csv_logger = CSVLogger('training.log', separator=',', append=False)\n",
        "\n",
        "        return self.model.fit(X,\n",
        "                              y,\n",
        "                              epochs=epochs,\n",
        "                              verbose=verbose,\n",
        "                              validation_split=validation_split,\n",
        "                              batch_size=batch_size,\n",
        "                              callbacks=[checkpoint, csv_logger])\n",
        "\n",
        "    def save_model(self):\n",
        "        self.model.save('./model_' + \n",
        "                        str(len(hiddenLayers)) + 'layers_'+\n",
        "                        str(self.regParam) + 'reg' +\n",
        "                        '.h5')\n",
        "\n",
        "    def summary(self):\n",
        "        return self.model.summary()\n",
        "\n",
        "    def plot_model(self):\n",
        "        plot_model(self.model)\n",
        "\n",
        "    def display_layers():\n",
        "        pass\n",
        "\n",
        "\n",
        "class NeuralNet(GoModel):\n",
        "    def __init__(self, regParam, learningRate, inputDim, outputDim,\n",
        "                 hiddenLayers, momentum):\n",
        "        GoModel.__init__(self, regParam, learningRate, inputDim, outputDim)\n",
        "        self.hidden_layers = hiddenLayers\n",
        "        self.momentum = momentum\n",
        "        self.num_layers = len(hiddenLayers)\n",
        "        self.model = self.buildModel()\n",
        "\n",
        "    def convLayer(self, x, numFilters, kernelSize):\n",
        "\n",
        "        x = Conv2D(filters=numFilters,\n",
        "                   kernel_size=kernelSize,\n",
        "                   data_format='channels_last',\n",
        "                   padding='same',\n",
        "                   use_bias=False,\n",
        "                   activation='linear',\n",
        "                   kernel_regularizer=regularizers.l2(self.regParam))(x)\n",
        "\n",
        "        # x = SpatialDropout2D(rate=0.2,\n",
        "        #                      data_format='channels_last')(x)\n",
        "\n",
        "        x = BatchNormalization(axis=-1)(x)\n",
        "\n",
        "        x = LeakyReLU()(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def residualLayer(self, inputLayer, numFilters, kernelSize):\n",
        "\n",
        "        x = self.convLayer(inputLayer, numFilters, kernelSize)\n",
        "\n",
        "        x = Conv2D(filters=numFilters,\n",
        "                   kernel_size=kernelSize,\n",
        "                   data_format='channels_last',\n",
        "                   padding='same',\n",
        "                   use_bias=False,\n",
        "                   activation='linear',\n",
        "                   kernel_regularizer=regularizers.l2(self.regParam))(x)\n",
        "\n",
        "        x = BatchNormalization(axis=-1)(x)\n",
        "\n",
        "        x = add([inputLayer, x])\n",
        "\n",
        "        x = LeakyReLU()(x)\n",
        "\n",
        "        return (x)\n",
        "\n",
        "    def value_head(self, x):\n",
        "\n",
        "        x = Conv2D(filters=1,\n",
        "                   kernel_size=(1, 1),\n",
        "                   data_format='channels_last',\n",
        "                   padding='same',\n",
        "                   use_bias=False,\n",
        "                   activation='linear',\n",
        "                   kernel_regularizer=regularizers.l2(self.regParam))(x)\n",
        "        \n",
        "        # x = SpatialDropout2D(rate=0.5,\n",
        "        #                      data_format='channels_last')(x)\n",
        "\n",
        "        x = BatchNormalization(axis=-1)(x)\n",
        "\n",
        "        x = LeakyReLU()(x)\n",
        "\n",
        "        x = Flatten()(x)\n",
        "\n",
        "        x = Dense(10,\n",
        "                  use_bias=False,\n",
        "                  activation='linear',\n",
        "                  kernel_regularizer=regularizers.l2(self.regParam))(x)\n",
        "\n",
        "        x = LeakyReLU()(x)\n",
        "\n",
        "        x = Dense(1,\n",
        "                  use_bias=False,\n",
        "                  activation='sigmoid',\n",
        "                  kernel_regularizer=regularizers.l2(self.regParam),\n",
        "                  name='value')(x)\n",
        "\n",
        "        return (x)\n",
        "\n",
        "    def policy_head(self, x):\n",
        "\n",
        "        x = Conv2D(filters=2,\n",
        "                   kernel_size=(1, 1),\n",
        "                   data_format='channels_last',\n",
        "                   padding='same',\n",
        "                   use_bias=False,\n",
        "                   activation='linear',\n",
        "                   kernel_regularizer=regularizers.l2(self.regParam))(x)\n",
        "\n",
        "        # x = SpatialDropout2D(rate=0.5,\n",
        "        #                      data_format='channels_last')(x)\n",
        "\n",
        "        x = BatchNormalization(axis=-1)(x)\n",
        "\n",
        "        x = LeakyReLU()(x)\n",
        "\n",
        "        x = Flatten()(x)\n",
        "\n",
        "        x = Dense(self.outputDim, activation='softmax', name='policy')(x)\n",
        "\n",
        "        return (x)\n",
        "\n",
        "    def buildModel(self):\n",
        "\n",
        "        mainInput = Input(shape=self.inputDim, name='board')\n",
        "\n",
        "        x = self.convLayer(mainInput, self.hidden_layers[0]['numFilters'],\n",
        "                           self.hidden_layers[0]['kernelSize'])\n",
        "\n",
        "        if len(self.hidden_layers) > 1:\n",
        "            for h in self.hidden_layers[1:]:\n",
        "                x = self.residualLayer(x, h['numFilters'], h['kernelSize'])\n",
        "\n",
        "        value_head = self.value_head(x)\n",
        "        policy_head = self.policy_head(x)\n",
        "\n",
        "        model = Model(inputs=[mainInput], outputs=[policy_head, value_head])\n",
        "        model.compile(optimizer=Adam(learning_rate=self.learningRate),\n",
        "                      loss={\n",
        "                          'value': 'mse',\n",
        "                          'policy': 'categorical_crossentropy'\n",
        "                      },\n",
        "                    #   loss_weights={\n",
        "                    #       'value': 0.5,\n",
        "                    #       'policy': 0.5\n",
        "                    #   },\n",
        "                      metrics=['accuracy'])\n",
        "\n",
        "        # model.compile(optimizer=SGD(lr=self.learningRate, momentum=self.momentum)\n",
        "        #               loss={\n",
        "        #                   'value': 'mse',\n",
        "        #                   'policy': 'categorical_crossentropy'\n",
        "        #               },\n",
        "        #               loss_weights={\n",
        "        #                   'value': 0.5,\n",
        "        #                   'policy': 0.5\n",
        "        #               },\n",
        "        #               metrics=['accuracy'])\n",
        "\n",
        "        return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sETUz717cPrQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tensorflow.__version__"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXtxUGZARTZR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# coding: utf-8\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "import numpy as np\n",
        "from tensorflow.keras import layers\n",
        "import golois\n",
        "\n",
        "\n",
        "planes = 8\n",
        "moves = 361\n",
        "dynamicBatch = True  # pour tester réseau sans installer la bibli golois\n",
        "if dynamicBatch:\n",
        "    N = 400000\n",
        "    input_data = np.random.randint(2, size=(N, 19, 19, planes))\n",
        "    input_data = input_data.astype('float32')\n",
        "\n",
        "    policy = np.random.randint(moves, size=(N, ))\n",
        "    policy = keras.utils.to_categorical(policy)\n",
        "\n",
        "    value = np.random.randint(2, size=(N, ))\n",
        "    value = value.astype('float32')\n",
        "\n",
        "    end = np.random.randint(2, size=(N, 19, 19, 2))\n",
        "    end = end.astype('float32')\n",
        "\n",
        "    golois.getBatch(input_data, policy, value, end)\n",
        "# else:\n",
        "#     input_data = np.load('./input_data.npy')\n",
        "#     policy = np.load('./policy.npy')\n",
        "#     value = np.load('./value.npy')\n",
        "#     end = np.load('./end.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTtNpFoHqW1Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_data.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKaUIHsKSo8h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 60\n",
        "REG_CONST = 0.001\n",
        "LEARNING_RATE = 0.1\n",
        "MOMENTUM = 0.9\n",
        "\n",
        "HIDDEN_CNN_LAYERS = [{\n",
        "    'numFilters': 64,\n",
        "    'kernelSize': (3, 3)\n",
        "}, {\n",
        "    'numFilters': 64,\n",
        "    'kernelSize': (3, 3)\n",
        "}, {\n",
        "    'numFilters': 64,\n",
        "    'kernelSize': (3, 3)\n",
        "}, {\n",
        "    'numFilters': 64,\n",
        "    'kernelSize': (3, 3)\n",
        "}]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyJxpxZkfbF3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nHiddenLayers = len(HIDDEN_CNN_LAYERS)\n",
        "print(len(HIDDEN_CNN_LAYERS))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XONlcqVRS1Hn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create Go Neural Network\n",
        "GoNeuralNet = NeuralNet(REG_CONST, LEARNING_RATE,\n",
        "                        (19, 19, planes), moves, HIDDEN_CNN_LAYERS,\n",
        "                        MOMENTUM)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zwvx-DeW-HQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Display summary of neural network\n",
        "GoNeuralNet.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pchGZL2YsZY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot model\n",
        "GoNeuralNet.plot_model()\n",
        "from IPython.display import Image\n",
        "Image('model.png');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TylBKS1XAlA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "GoNeuralNet.fit(input_data, {\n",
        "    'policy': policy,\n",
        "    'value': value\n",
        "},\n",
        "                epochs=60,\n",
        "                verbose=1,\n",
        "                validation_split=0.1,\n",
        "                batch_size=BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbRfz8FinAE9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('./training.log')\n",
        "epochs = df['epoch']\n",
        "plt.clf()\n",
        "f, ax = plt.subplots(2, 3, figsize=(20,10))\n",
        "ax[0][0].plot(epochs, df['loss'])\n",
        "ax[0][0].plot(epochs, df['val_loss'])\n",
        "ax[0][0].legend(['loss', 'val_los'])\n",
        "ax[0][0].set_title('Total loss')\n",
        "ax[0][1].plot(epochs, df['policy_loss'])\n",
        "ax[0][1].plot(epochs, df['val_policy_loss'])\n",
        "ax[0][1].legend(['policy_loss', 'val_policy_loss'])\n",
        "ax[0][1].set_title('Policy loss')\n",
        "ax[0][2].plot(epochs, df['value_loss'])\n",
        "ax[0][2].plot(epochs, df['val_value_loss'])\n",
        "ax[0][2].legend(['value_loss', 'val_value_loss'])\n",
        "ax[0][2].set_title('Value loss')\n",
        "ax[1][1].plot(epochs, df['policy_acc'])\n",
        "ax[1][1].plot(epochs, df['val_policy_acc'])\n",
        "ax[1][1].legend(['policy_acc', 'val_policy_acc'])\n",
        "ax[1][1].set_title('Policy acc')\n",
        "ax[1][2].plot(epochs, df['value_acc'])\n",
        "ax[1][2].plot(epochs, df['val_value_acc'])\n",
        "ax[1][2].legend(['value_acc', 'val_value_acc'])\n",
        "ax[1][2].set_title('Value accuarcy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcQF-w9JnLpi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a=list(df.columns)\n",
        "print(a)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYxEcgnKXDPN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "GoNeuralNet.save_model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyPJi-rBoD2R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls -all"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xws6p6WqoCFf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download('model_' + \n",
        "                        str(len(hiddenLayers)) + 'layers_'+\n",
        "                        str(self.regParam) + 'reg' +\n",
        "                        '.h5')\n",
        "files.download('training.log')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y77BynqUgIve",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}